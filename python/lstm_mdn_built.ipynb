{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a87cfe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_probability\n",
      "  Using cached tensorflow_probability-0.25.0-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow_probability) (2.3.1)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow_probability) (1.17.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow_probability) (2.1.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow_probability) (5.1.1)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow_probability) (3.0.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow_probability) (0.6.0)\n",
      "Collecting dm-tree (from tensorflow_probability)\n",
      "  Using cached dm_tree-0.1.9-cp313-cp313-win_amd64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: attrs>=18.2.0 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from dm-tree->tensorflow_probability) (24.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from dm-tree->tensorflow_probability) (1.17.0)\n",
      "Using cached tensorflow_probability-0.25.0-py2.py3-none-any.whl (7.0 MB)\n",
      "Using cached dm_tree-0.1.9-cp313-cp313-win_amd64.whl (102 kB)\n",
      "Installing collected packages: dm-tree, tensorflow_probability\n",
      "\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   -------------------- ------------------- 1/2 [tensorflow_probability]\n",
      "   ---------------------------------------- 2/2 [tensorflow_probability]\n",
      "\n",
      "Successfully installed dm-tree-0.1.9 tensorflow_probability-0.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92c9096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Using cached tf_keras-2.20.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tf-keras) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2025.6.15)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.8)\n",
      "Requirement already satisfied: pillow in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (11.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\falgun dadhich\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Using cached tf_keras-2.20.1-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "569953af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-mdn-layer\n",
      "  Downloading keras-mdn-layer-0.3.0.tar.gz (6.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: keras-mdn-layer\n",
      "  Building wheel for keras-mdn-layer (setup.py): started\n",
      "  Building wheel for keras-mdn-layer (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-mdn-layer: filename=keras_mdn_layer-0.3.0-py3-none-any.whl size=7064 sha256=154e6f5670195b101415bda809a79882c2ac27b7488f3945afe3042d993e6b55\n",
      "  Stored in directory: c:\\users\\falgun dadhich\\appdata\\local\\pip\\cache\\wheels\\ca\\3b\\51\\b50e5cb62d37846fd7421e54c668f70e3946e31a5a52ea2759\n",
      "Successfully built keras-mdn-layer\n",
      "Installing collected packages: keras-mdn-layer\n",
      "Successfully installed keras-mdn-layer-0.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'keras-mdn-layer' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'keras-mdn-layer'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-mdn-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "700ef9a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.compat.v1.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping, TensorBoard\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distributions \u001b[38;5;28;01mas\u001b[39;00m tfd\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmdn\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m     26\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Falgun Dadhich\\anaconda3\\Lib\\site-packages\\mdn\\__init__.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m K\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.compat.v1.keras'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "LSTM–MDN for Value-at-Risk forecasting\n",
    "EXTENDED from indices → NIFTY100 stocks\n",
    "MODEL TYPES UNCHANGED\n",
    "\"\"\"\n",
    "\n",
    "# ===============================\n",
    "# DEPENDENCIES (UNCHANGED)\n",
    "# ===============================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import mdn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ===============================\n",
    "# REPRODUCIBILITY (UNCHANGED)\n",
    "# ===============================\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "np.random.seed(6969)\n",
    "rn.seed(6969)\n",
    "tf.random.set_seed(6969)\n",
    "\n",
    "# ===============================\n",
    "# PARAMETERS (UNCHANGED)\n",
    "# ===============================\n",
    "\n",
    "d = 10\n",
    "test_start_date = \"2021-01-01\"\n",
    "test_end_date   = \"2022-12-31\"\n",
    "\n",
    "save_results = True\n",
    "period_appendix = \"_nifty100\"\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='tbdir/', histogram_freq=0)\n",
    "mon = EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# ===============================\n",
    "# LOAD NIFTY100 STOCK LIST\n",
    "# ===============================\n",
    "\n",
    "stocks = pd.read_csv(\"data/nifty100_constituents.csv\")[\"Symbol\"].tolist()\n",
    "\n",
    "# ===============================\n",
    "# UTILITIES (UNCHANGED)\n",
    "# ===============================\n",
    "\n",
    "def df_to_X_y(df, window_size=10):\n",
    "    df_as_np = df.to_numpy()\n",
    "    X, y = [], []\n",
    "    for i in range(len(df_as_np) - window_size):\n",
    "        X.append([[a] for a in df_as_np[i:i+window_size]])\n",
    "        y.append(df_as_np[i + window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# ===============================\n",
    "# MDN LOSS (UNCHANGED)\n",
    "# ===============================\n",
    "\n",
    "def get_mixture_loss_func_REGULARIZED(output_dim, num_mixes, lambda_reg=0.2):\n",
    "    def mdn_loss_func(y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, [-1, (2*num_mixes*output_dim)+num_mixes])\n",
    "        y_true = tf.reshape(y_true, [-1, output_dim])\n",
    "\n",
    "        out_mu, out_sigma, out_pi = tf.split(\n",
    "            y_pred,\n",
    "            [num_mixes*output_dim, num_mixes*output_dim, num_mixes],\n",
    "            axis=-1\n",
    "        )\n",
    "\n",
    "        cat = tfd.Categorical(logits=out_pi)\n",
    "        mus = tf.split(out_mu, num_mixes, axis=1)\n",
    "        sigs = tf.split(out_sigma, num_mixes, axis=1)\n",
    "        components = [\n",
    "            tfd.MultivariateNormalDiag(loc=m, scale_diag=s)\n",
    "            for m, s in zip(mus, sigs)\n",
    "        ]\n",
    "\n",
    "        mixture = tfd.Mixture(cat=cat, components=components)\n",
    "        loss = -tf.reduce_mean(mixture.log_prob(y_true))\n",
    "        loss += lambda_reg * tf.reduce_sum(tf.square(out_pi))\n",
    "        return loss\n",
    "    return mdn_loss_func\n",
    "\n",
    "# ===============================\n",
    "# MDN OUTPUT PARSING (UNCHANGED)\n",
    "# ===============================\n",
    "\n",
    "def get_outputs(predictions, N_MIXES=2):\n",
    "    mus = predictions[:, :N_MIXES]\n",
    "    sigs = predictions[:, N_MIXES:2*N_MIXES]\n",
    "    pis = mdn.softmax(predictions[:, -N_MIXES:])\n",
    "    return mus, sigs, pis\n",
    "\n",
    "def MDN_predict(model, test_data, N_MIXES=2):\n",
    "    preds = model.predict(test_data)\n",
    "    mu, sigma, pi = get_outputs(preds, N_MIXES)\n",
    "    return {\"mu\": mu, \"sigma\": sigma, \"pi\": pi}\n",
    "\n",
    "def dataframe_converter(pred, N_MIXES=2):\n",
    "    cols = []\n",
    "    for i in range(1, N_MIXES+1): cols.append(f\"mu{i}\")\n",
    "    for i in range(1, N_MIXES+1): cols.append(f\"sigma{i}\")\n",
    "    for i in range(1, N_MIXES+1): cols.append(f\"pi{i}\")\n",
    "    return pd.DataFrame(\n",
    "        np.column_stack([pred[\"mu\"], pred[\"sigma\"], pred[\"pi\"]]),\n",
    "        columns=cols\n",
    "    )\n",
    "\n",
    "# ===============================\n",
    "# MAIN LOOP — PER STOCK\n",
    "# ===============================\n",
    "\n",
    "for stock in stocks:\n",
    "\n",
    "    print(f\"Training MDN models for {stock}\")\n",
    "\n",
    "    df = pd.read_csv(f\"data/prices/{stock}.csv\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "    test_start_idx = df[df[\"date\"] > test_start_date].index.min() - d\n",
    "    test_data = df.iloc[test_start_idx:]\n",
    "    train_data = df.iloc[:test_start_idx]\n",
    "\n",
    "    X_train, y_train = df_to_X_y(train_data[\"R\"], d)\n",
    "    X_test, y_test   = df_to_X_y(test_data[\"R\"], d)\n",
    "\n",
    "    # ===============================\n",
    "    # MODEL 1 — 2 MIX (VANILLA)\n",
    "    # ===============================\n",
    "\n",
    "    model_plain = Sequential([\n",
    "        InputLayer(input_shape=(d,1)),\n",
    "        LSTM(6, activation=\"relu\"),\n",
    "        Dense(10, activation=\"relu\"),\n",
    "        mdn.MDN(1, 2)\n",
    "    ])\n",
    "\n",
    "    model_plain.compile(\n",
    "        loss=mdn.get_mixture_loss_func(1,2),\n",
    "        optimizer=keras.optimizers.Adam()\n",
    "    )\n",
    "\n",
    "    model_plain.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        callbacks=[mon, tensorboard],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # ===============================\n",
    "    # MODEL 2 — 2 MIX REGULARIZED\n",
    "    # ===============================\n",
    "\n",
    "    model_reg = Sequential([\n",
    "        InputLayer(input_shape=(d,1)),\n",
    "        LSTM(6, activation=\"relu\"),\n",
    "        Dense(10, activation=\"relu\"),\n",
    "        mdn.MDN(1, 2)\n",
    "    ])\n",
    "\n",
    "    model_reg.compile(\n",
    "        loss=get_mixture_loss_func_REGULARIZED(1,2,0.1),\n",
    "        optimizer=keras.optimizers.Adam()\n",
    "    )\n",
    "\n",
    "    model_reg.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        callbacks=[mon, tensorboard],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # ===============================\n",
    "    # MODEL 3 — 3 MIX (FINAL MODEL)\n",
    "    # ===============================\n",
    "\n",
    "    model_C3 = Sequential([\n",
    "        InputLayer(input_shape=(d,1)),\n",
    "        LSTM(6, activation=\"relu\"),\n",
    "        Dense(10, activation=\"relu\"),\n",
    "        mdn.MDN(1, 3)\n",
    "    ])\n",
    "\n",
    "    model_C3.compile(\n",
    "        loss=mdn.get_mixture_loss_func(1,3),\n",
    "        optimizer=keras.optimizers.Adam()\n",
    "    )\n",
    "\n",
    "    model_C3.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        callbacks=[mon, tensorboard],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # ===============================\n",
    "    # SAVE RESULTS (UNCHANGED FORMAT)\n",
    "    # ===============================\n",
    "\n",
    "    if save_results:\n",
    "        out = dataframe_converter(\n",
    "            MDN_predict(model_C3, X_test, 3),\n",
    "            3\n",
    "        )\n",
    "        out.to_csv(\n",
    "            f\"results/mdn_outputs/{stock}_C3{period_appendix}.csv\",\n",
    "            index=False\n",
    "        )\n",
    "\n",
    "    tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc21bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
